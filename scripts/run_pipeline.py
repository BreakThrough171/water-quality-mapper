#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì „êµ­ ìˆ˜ì§ˆ í‰ê°€ ì‹œìŠ¤í…œ íŒŒì´í”„ë¼ì¸
ì „ì²´ ì‹œìŠ¤í…œì„ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
"""

import sys
import os
from datetime import datetime
import schedule
import time
from typing import List, Dict
import pandas as pd

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.data_collection.api_client import WaterQualityAPIClient
from src.data_collection.data_collector import WaterQualityCollector
from src.data_processing.preprocessor import DataPreprocessor
from src.data_processing.data_processor import WaterQualityProcessor
from src.risk_assessment.risk_calculator import RiskCalculator
from src.risk_assessment.alert_system import AlertSystem
from src.visualization.map_generator import MapGenerator
from src.visualization.chart_generator import ChartGenerator
from src.web_publisher.web_publisher import WebPublisher
from src.utils.config import config
from src.utils.logger import logger

class WaterQualityPipeline:
    """ìˆ˜ì§ˆ í‰ê°€ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.api_client = WaterQualityAPIClient()
        self.collector = WaterQualityCollector()
        self.preprocessor = DataPreprocessor()
        self.processor = WaterQualityProcessor()
        self.risk_calculator = RiskCalculator()
        self.alert_system = AlertSystem()
        self.map_generator = MapGenerator()
        self.chart_generator = ChartGenerator()
        self.web_publisher = WebPublisher()
    
    def run_full_pipeline(self) -> bool:
        """
        ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Returns:
            bool: ì‹¤í–‰ ì„±ê³µ ì—¬ë¶€
        """
        try:
            logger.info("=" * 60)
            logger.info("ì „êµ­ ìˆ˜ì§ˆ í‰ê°€ ì‹œìŠ¤í…œ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            logger.info(f"ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info("=" * 60)
            
            # 1. ë°ì´í„° ìˆ˜ì§‘ (ìƒˆë¡œìš´ êµ¬ì¡°: API â†’ CSV ì—…ë°ì´íŠ¸ â†’ ê¸°ì¡´ CSV)
            logger.info("\n1ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘")
            raw_data = self.collector.collect_data()
            
            if raw_data is None or raw_data.empty:
                logger.error("ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            logger.info(f"âœ… ìˆ˜ì§‘ëœ ë°ì´í„°: {len(raw_data)}ê°œ ì¸¡ì •ì†Œ")
            
            # 2. ë°ì´í„° ì „ì²˜ë¦¬
            logger.info("\n2ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬")
            processed_data = self.preprocessor.preprocess_water_quality_data(raw_data)
            
            if processed_data is None:
                logger.error("ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤íŒ¨.")
                return False
            
            logger.info(f"âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„°: {len(processed_data)}ê°œ ë ˆì½”ë“œ")
            
            # 3. ìœ„í—˜ë„ ê³„ì‚°
            logger.info("\n3ë‹¨ê³„: ìœ„í—˜ë„ ê³„ì‚°")
            risk_data = self.risk_calculator.calculate_risk_scores(processed_data)
            
            if risk_data is None:
                logger.error("ìœ„í—˜ë„ ê³„ì‚° ì‹¤íŒ¨.")
                return False
            
            logger.info(f"âœ… ìœ„í—˜ë„ ê³„ì‚° ì™„ë£Œ: {len(risk_data)}ê°œ ë ˆì½”ë“œ")
            
            # 4. ì§€ì—­ë³„ ìœ„í—˜ë„ ê³„ì‚°
            logger.info("\n4ë‹¨ê³„: ì§€ì—­ë³„ ìœ„í—˜ë„ ê³„ì‚°")
            regional_data = self.risk_calculator.calculate_regional_risk(risk_data)
            
            if regional_data is None:
                logger.warning("ì§€ì—­ë³„ ìœ„í—˜ë„ ê³„ì‚° ì‹¤íŒ¨. ê¸°ë³¸ ë°ì´í„° ì‚¬ìš©.")
                regional_data = risk_data
            
            # 5. ê³ ìœ„í—˜ ì§€ì—­ ì‹ë³„
            logger.info("\n5ë‹¨ê³„: ê³ ìœ„í—˜ ì§€ì—­ ì‹ë³„")
            high_risk_areas = self.risk_calculator.identify_high_risk_areas(risk_data)
            
            if high_risk_areas is not None:
                logger.info(f"âœ… ê³ ìœ„í—˜ ì§€ì—­ ì‹ë³„: {len(high_risk_areas)}ê°œ ì§€ì—­")
            else:
                logger.warning("ê³ ìœ„í—˜ ì§€ì—­ ì‹ë³„ ì‹¤íŒ¨.")
            
            # 6. ê²½ë³´ ìƒì„±
            logger.info("\n6ë‹¨ê³„: ê²½ë³´ ì‹œìŠ¤í…œ")
            alerts = self.alert_system.generate_alerts(risk_data, high_risk_areas)
            
            if alerts:
                logger.info(f"âœ… ê²½ë³´ ìƒì„±: {len(alerts)}ê°œ")
            else:
                logger.info("ê²½ë³´ ì—†ìŒ")
            
            # 7. ì§€ë„ ìƒì„±
            logger.info("\n7ë‹¨ê³„: ì§€ë„ ìƒì„±")
            map_file = self._generate_map(risk_data, regional_data)
            
            if map_file:
                logger.info(f"âœ… ì§€ë„ ìƒì„± ì™„ë£Œ: {map_file}")
            else:
                logger.error("ì§€ë„ ìƒì„± ì‹¤íŒ¨.")
                return False
            
            # 8. ì°¨íŠ¸ ìƒì„±
            logger.info("\n8ë‹¨ê³„: ì°¨íŠ¸ ìƒì„±")
            chart_files = self._generate_charts(risk_data, regional_data)
            
            if chart_files:
                logger.info(f"âœ… ì°¨íŠ¸ ìƒì„± ì™„ë£Œ: {len(chart_files)}ê°œ")
            else:
                logger.warning("ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨.")
            
            # 9. ì›¹ ê²Œì‹œ
            logger.info("\n9ë‹¨ê³„: ì›¹ ê²Œì‹œ")
            web_files = self._publish_to_web(map_file, chart_files)
            
            if web_files:
                logger.info(f"âœ… ì›¹ ê²Œì‹œ ì™„ë£Œ: {len(web_files)}ê°œ íŒŒì¼")
            else:
                logger.warning("ì›¹ ê²Œì‹œ ì‹¤íŒ¨.")
            
            # 10. ê²°ê³¼ ìš”ì•½
            logger.info("\n10ë‹¨ê³„: ê²°ê³¼ ìš”ì•½")
            self._print_summary(risk_data, regional_data, high_risk_areas, alerts)
            
            logger.info("\n" + "=" * 60)
            logger.info("âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ")
            logger.info("=" * 60)
            
            return True
            
        except Exception as e:
            logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False
    
    def _generate_map(self, risk_data: pd.DataFrame, regional_data: pd.DataFrame = None) -> str:
        """
        ì§€ë„ ìƒì„±
        
        Args:
            risk_data: ìœ„í—˜ë„ ë°ì´í„°
            regional_data: ì§€ì—­ë³„ ë°ì´í„°
            
        Returns:
            str: ìƒì„±ëœ ì§€ë„ íŒŒì¼ ê²½ë¡œ
        """
        try:
            map_file = self.map_generator.create_integrated_map(risk_data, regional_data)
            return map_file
        except Exception as e:
            logger.error(f"ì§€ë„ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _generate_charts(self, risk_data: pd.DataFrame, regional_data: pd.DataFrame = None,
                        trend_data: Dict = None) -> List[str]:
        """
        ì°¨íŠ¸ ìƒì„±
        
        Args:
            risk_data: ìœ„í—˜ë„ ë°ì´í„°
            regional_data: ì§€ì—­ë³„ ë°ì´í„°
            trend_data: íŠ¸ë Œë“œ ë°ì´í„°
            
        Returns:
            List[str]: ìƒì„±ëœ ì°¨íŠ¸ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        try:
            chart_files = []
            
            # ìœ„í—˜ë„ ë¶„í¬ ì°¨íŠ¸
            risk_chart = self.chart_generator.create_risk_distribution_chart(risk_data)
            if risk_chart:
                chart_files.append(risk_chart)
            
            # ì§€ì—­ë³„ ë¹„êµ ì°¨íŠ¸
            if regional_data is not None:
                regional_chart = self.chart_generator.create_regional_comparison_chart(regional_data)
                if regional_chart:
                    chart_files.append(regional_chart)
            
            # íŠ¸ë Œë“œ ë¶„ì„ ì°¨íŠ¸
            if trend_data:
                trend_chart = self.chart_generator.create_trend_analysis_chart(trend_data)
                if trend_chart:
                    chart_files.append(trend_chart)
            
            # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
            correlation_chart = self.chart_generator.create_correlation_heatmap(risk_data)
            if correlation_chart:
                chart_files.append(correlation_chart)
            
            # ì¢…í•© ëŒ€ì‹œë³´ë“œ
            dashboard_chart = self.chart_generator.create_summary_dashboard(risk_data, regional_data)
            if dashboard_chart:
                chart_files.append(dashboard_chart)
            
            return chart_files
            
        except Exception as e:
            logger.error(f"ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def _publish_to_web(self, map_file: str, chart_files: List[str]) -> List[str]:
        """
        ì›¹ ê²Œì‹œ
        
        Args:
            map_file: ì§€ë„ íŒŒì¼ ê²½ë¡œ
            chart_files: ì°¨íŠ¸ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            List[str]: ê²Œì‹œëœ ì›¹ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        try:
            web_files = self.web_publisher.publish_results(map_file, chart_files)
            return web_files
        except Exception as e:
            logger.error(f"ì›¹ ê²Œì‹œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def _print_summary(self, risk_data: pd.DataFrame, regional_data: pd.DataFrame = None,
                      high_risk_areas: pd.DataFrame = None, alerts: List = None):
        """
        ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        
        Args:
            risk_data: ìœ„í—˜ë„ ë°ì´í„°
            regional_data: ì§€ì—­ë³„ ë°ì´í„°
            high_risk_areas: ê³ ìœ„í—˜ ì§€ì—­
            alerts: ê²½ë³´ ë¦¬ìŠ¤íŠ¸
        """
        try:
            logger.info("\nğŸ“Š ê²°ê³¼ ìš”ì•½")
            logger.info("-" * 40)
            
            # ê¸°ë³¸ í†µê³„
            if risk_data is not None:
                logger.info(f"ğŸ“ˆ ì´ ì¸¡ì •ì†Œ ìˆ˜: {len(risk_data)}ê°œ")
                logger.info(f"ğŸ“Š í‰ê·  ìœ„í—˜ë„ ì ìˆ˜: {risk_data['weighted_score'].mean():.4f}")
                logger.info(f"ğŸ“Š ìµœëŒ€ ìœ„í—˜ë„ ì ìˆ˜: {risk_data['weighted_score'].max():.4f}")
                logger.info(f"ğŸ“Š ìµœì†Œ ìœ„í—˜ë„ ì ìˆ˜: {risk_data['weighted_score'].min():.4f}")
            
            # ì§€ì—­ë³„ í†µê³„
            if regional_data is not None:
                logger.info(f"ğŸ—ºï¸ ë¶„ì„ ì§€ì—­ ìˆ˜: {len(regional_data)}ê°œ")
            
            # ê³ ìœ„í—˜ ì§€ì—­
            if high_risk_areas is not None and not high_risk_areas.empty:
                logger.info(f"âš ï¸ ê³ ìœ„í—˜ ì§€ì—­ ìˆ˜: {len(high_risk_areas)}ê°œ")
                for idx, row in high_risk_areas.head().iterrows():
                    logger.info(f"   - {row.get('ptNm', 'Unknown')}: {row.get('weighted_score', 0):.4f}")
            
            # ê²½ë³´
            if alerts:
                logger.info(f"ğŸš¨ í™œì„± ê²½ë³´ ìˆ˜: {len(alerts)}ê°œ")
                for alert in alerts[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                    logger.info(f"   - {alert}")
            
            logger.info("-" * 40)
            
        except Exception as e:
            logger.error(f"ê²°ê³¼ ìš”ì•½ ì¶œë ¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    def run_scheduled_pipeline(self):
        """ìŠ¤ì¼€ì¤„ëœ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info(f"ğŸ• ìŠ¤ì¼€ì¤„ ì‹¤í–‰: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        self.run_full_pipeline()
    
    def setup_scheduler(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •"""
        update_time = config.get_update_time()
        schedule.every(update_time).minutes.do(self.run_scheduled_pipeline)
        
        logger.info(f"â° ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • ì™„ë£Œ: {update_time}ë¶„ë§ˆë‹¤ ì‹¤í–‰")
        
        while True:
            schedule.run_pending()
            time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ì „êµ­ ìˆ˜ì§ˆ í‰ê°€ ì‹œìŠ¤í…œ íŒŒì´í”„ë¼ì¸')
    parser.add_argument('--mode', choices=['run', 'schedule', 'test'], 
                       default='run', help='ì‹¤í–‰ ëª¨ë“œ')
    parser.add_argument('--test', action='store_true', help='í…ŒìŠ¤íŠ¸ ëª¨ë“œ')
    
    args = parser.parse_args()
    
    pipeline = WaterQualityPipeline()
    
    if args.mode == 'schedule':
        logger.info("ğŸ”„ ìŠ¤ì¼€ì¤„ ëª¨ë“œë¡œ ì‹¤í–‰")
        pipeline.setup_scheduler()
    elif args.mode == 'test' or args.test:
        logger.info("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ ì‹¤í–‰")
        # í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨í•œ ì‹¤í–‰
        success = pipeline.run_full_pipeline()
        if success:
            logger.info("âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        else:
            logger.error("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
    else:
        logger.info("â–¶ï¸ ì¼ë°˜ ëª¨ë“œë¡œ ì‹¤í–‰")
        success = pipeline.run_full_pipeline()
        if success:
            logger.info("âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì„±ê³µ")
        else:
            logger.error("âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨")

if __name__ == "__main__":
    main() 